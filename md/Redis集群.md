# Redis 集群篇

## Codis

### Codis 的优点

#### 分布式设计简单

将分布式的问题交给了第三方 zk/etcd 去负责，自己就省去了复杂的分布式一致性代码的编写维护工作。

而 Redis Cluster 的内部实现非常复杂，它为了实现去中心化，混合使用了复杂的 Raft 和 Gossip 协议，还有大量的需要调优的配置参数，当集群出现故障时，维护人员往往不知道从何处着手。

### MGET 指令

mget 指令用于批量获取多个 key 的值，这些 key 可能会分布在多个 Redis 实例中。

#### 工作原理

思路类似MapReduce，Codis 将 key 按照所分配的Redis 实例打散分组，然后依次对每个Redis 实例调用 mget 方法，最后将结果汇总为一个，再返回给客户端。

## Redis Cluster

由 Redis 作者自己提供的 Redis 集群化方案。

[Redis 高可用集群原理和实践](https://www.51cto.com/article/710347.html)

### 特点

#### 去中心化

它采用了去中心化的方式，由每个节点负责整个集群的一部分数据，但每个节点负责的数据多少可能不一样。一般最少需要 3 个 「主节点」 节点。

![Redis 集群](https://s9.51cto.com/oss/202205/31/1700ed6335147dc56415764d4d05c352aaa5db.jpg)

#### 交互方式

节点之间相互连接组成一个对等的集群，它们之间通过 Gossip 协议相互交互集群信息。

#### 数据槽位

Redis Cluster 将所有数据划分为 **16384(2^14)** 的 slots，它比 Codis 的 1024 个槽划分的更为精细。

##### 节点端

每个节点负责其中一部分槽位，但槽位信息却存储在每个节点中。

这种方式与 Codis不同，因此它不需要另外的分布式存储来存储节点槽位信息。

##### 客户端

当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息，因此当客户端要查找某个 key 时，可以直接定位到目标节点。

这种方式也与 Codis不同，Codis 需要通过 Proxy 来定位目标节点，RedisCluster 是直接定位。

客户端为了可以直接定位某个具体的 key 所在的节点，它就需要缓存槽位相关信息，这样才可以准确快速地定位到相应的节点。

同时因为**槽位信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整**。

##### 槽位定位算法

Cluster 默认的槽位算法与 Codis 基本相同，区别在于 Cluster 默认采用 crc16 算法进行 hash 运算 ，且取模值固定为16384。

但 Cluster 允许用户强制某个 key 挂在特定槽位上。

### 跳转

当客户端向一个错误的节点发出了指令，该节点会发现指令中的 key 所在的槽位并不归自己管理，

这时节点会向客户端返回一个 MOVED 指令，携带了key的所在槽位编号和目标节点地址，告诉客户端去连这个节点去获取数据。

客户端收到 MOVED 指令后，要立即纠正本地的槽位映射表。后续所有 key 将使用新的槽位映射表。

### 迁移

工具 redis-trib 可以让运维人员手动调整槽位的分配情况。

#### 工作原理

Redis 迁移的单位是槽，当一个槽正在迁移时，这个槽就处于中间过渡状态。

这个槽在原节点的状态为migrating，在目标节点的状态为importing，表示数据正在从源流向目标。

redis-trib首先会将「原节点」和「目标节点」设置好中间过渡状态，然后一次性获取原节点槽位的所有 key 列表（通过`keysinslot`指令，也可以部分获取），之后挨个进行迁移。

##### 1. 从原节点获取内容

「原节点」对单个key 执行dump指令得到序列化内容

##### 2. 存到目标节点

「原节点」向「目标节点」发送指令restore ，参数为携带的序列化内容，「目标节点」再进行反序列化就可以将内容恢复到内存中

##### 3. 从原节点删除内容

「目标节点」返回 OK，「原节点」收到后再把当前节点的key删除掉

需要强调的是，在目标节点执行restore指令到原节点删除key之间，原节点的主线程会处于阻塞状态，直到key被成功删除。

#### 处理网络故障

如果迁移过程中突然出现网络故障，导致这个槽的迁移只进行了一半，但此时两个节点依旧处于中间过渡状态。等到迁移工具重新连上时，会提示用户继续进行迁移。

#### 避免大key

在迁移过程中，如果每个key的内容都很小，migrate指令执行会很快，它就并不会影响客户端的正常访问。

如果key的内容很大，因为migrate指令是阻塞指令会同时导致原节点和目标节点卡顿，影响集群的稳定型。

#### 迁移过程中的客户端访问流程

1.首先新旧两个节点对应的槽位都存在部分 key 数据。

2.客户端先尝试访问旧节点，如果对应的数据还在旧节点里面，那么旧节点正常处理。

3.如果对应的数据不在旧节点里面，那么有两种可能，要么该数据在新节点里，要么根本就不存在。

3.1 旧节点会向客户端返回一个 `-ASK targetNodeAddr` 的重定向指令。

3.2 客户端收到这个重定向指令后，先去目标节点执行一个不带任何参数的 `asking` 指令，然后在目标节点再重新执行原先的操作指令。

##### 为什么需要执行一个不带参数的 asking 指令呢？

因为在迁移没有完成之前，按理说这个槽位还是不归「目标节点」管理的，如果这个时候向「目标节点」发送该槽位的指令，节点是不认的，

所以它会向客户端返回一个 `-MOVED` 重定向指令告诉它去「原节点」去执行，如此就会形成「重定向循环」。

`asking` 指令就是为了告诉「目标节点」下一条指令不能不理，而要当成自己的槽位来处理。

#### 迁移效率

迁移是会影响服务效率的，同样的指令在正常情况下一个 ttl 就能完成，而在迁移中得 3 个 ttl 才能搞定。

#### 槽位迁移感知

如果 Cluster 中某个槽位正在迁移或者已经迁移完了，client 如何能感知到槽位的变化呢？

客户端保存了槽位和节点的映射关系表，它需要即时得到更新，才可以正常地将某条指令发到正确的节点中。

##### 两个特殊的 error 指令

第一个 `moved` 是用来纠正槽位的，在错误访问导致的「跳转」中使用。

它会让客户端刷新自己的槽位关系表，然后重试指令，后续所有打在该槽位的指令都会转到目标节点。

第二个 `asking` 指令和 `moved` 不一样，它是用来临时纠正槽位的，在「迁移」过程中使用。

因此客户端不会刷新槽位映射关系表，因为它只是临时纠正该指令的槽位信息，不影响后续指令。

##### 重试 2 次

moved 和 asking 指令都是重试指令，客户端会因为这两个指令多重试一次。

当一条指令被发送到错误的节点，这个节点会先给你一个 moved 错误告知你去另外一个节点重试。

所以客户端就去另外一个节点重试了，结果刚好这个时候运维人员要对这个槽位进行迁移操作。

于是给客户端回复了一个 asking 指令告知客户端去目标节点去重试指令。

这里客户端重试了 2 次。

##### 重试多次

在某些特殊情况下，客户端甚至会重试多次，所以客户端的源码里在执行指令时都会有一个循环，然后会设置一个最大重试次数，Java 和 Python 都有这个参数，只是设置的值不一样。

当重试次数超过这个值时，客户端会直接向业务层抛出异常。

### 容错

Redis Cluster 可以为每个「主节点」设置若干个「从节点」，单「主节点」故障时，集群会自动将其中某个「从节点」提升为「主节点」。

如果某个「主节点」没有「从节点」，那么当它发生故障时，集群将完全处于不可用状态。

不过 Redis 也提供了一个参数 cluster-require-full-coverage 可以允许部分节点故障，其它节点还可以继续提供对外访问。

### 网络抖动

指突然之间部分连接变得不可访问，然后很快又恢复正常。

#### 解决方法

为解决这种问题，Redis Cluster 提供了一种选项 `cluster-node-timeout`，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。

还有另外一个选项 `cluster-slave-validity-factor` 作为倍乘系数来放大这个超时时间来宽松容错的紧急程度。如果这个系数为零，那么主从切换是不会抗拒网络抖动的。如果这个系数大于 1，它就成了主从切换的松弛系数。

### 可能下线 (PFAIL-Possibly Fail) 与确定下线 (Fail)

因为 Redis Cluster 是去中心化的，一个节点认为某个节点失联了并不代表所有的节点都认为它失联了。

所以集群还得经过一次协商的过程，只有当大多数节点都认定了某个节点失联了，集群才认为该节点需要进行主从切换来容错。

Redis 集群节点采用 Gossip 协议来广播自己的状态以及自己对整个集群认知的改变。

#### 协商过程

1.一个节点发现某个节点失联了 (PFail)，它会将这条信息向整个集群广播，其它节点也就可以收到这点失联信息。

2.如果一个节点收到了某个节点失联的数量 (PFail Count) 已经达到了集群的大多数，就可以标记该节点为确定下线状态 (Fail)

3.向整个集群广播，强迫其它节点也接收该节点已经下线的事实，并立即对该失联节点进行主从切换。

### 集群变更感知

当服务器节点变更时，客户端应该即时得到通知以实时刷新自己的节点关系表。

这里要分 2 种情况：

1.目标节点挂掉了

客户端会收到一个 ConnectionError，紧接着会随机挑一个节点来重试，这时被重试的节点会通过 moved error 告知目标槽位被分配到的新的节点地址。

2.运维手动修改了集群信息，将 「主节点」 切换到其它节点，并将旧的 「主节点」 移除集群。

客户端会收到一个 ClusterDown 的错误，被告知当前节点所在集群不可用 (当前节点已经被孤立了，它不再属于之前的集群)。

这时客户端就会关闭所有的连接，清空槽位映射关系表，然后向上层抛错。

待下一条指令过来时，就会重新尝试初始化节点信息。

# Info 指令

## 信息种类

### 1、`Server` - 服务器运行的环境参数

### 2、`Clients` - 客户端相关信息

### 3、`Memory` - 服务器运行内存统计数据

### 4、`Persistence` - 持久化信息

### 5、`Stats` - 通用统计数据

### 6、`Replication` - 主从复制相关信息

### 7、`CPU` - CPU 使用情况

### 8、`Cluster` - 集群信息

### 9、`KeySpace` - 键值对统计数量信息

## 使用方法

Info 可以一次性获取所有的信息，也可以按块取信息。

### Redis 每秒执行多少次指令？

`redis-cli info stats |grep ops`

instantaneous_ops_per_sec 表示瞬时每秒操作数

### Redis 连接了多少客户端？

`redis-cli info clients`

connected_client 表示正在连接的客户端数量

`client list` 指令可以列出所有的客户端链接地址，并以此来确定源头

`redis-cli info stats |grep reject`

rejected_connections 表示因为超出最大连接数限制而被拒绝的客户端连接次数

如果这个数字很大，意味着服务器的最大连接数设置的过低需要调整 `maxclients` 参数。

### Redis 内存占用多大 ?

`redis-cli info memory | grep used | grep human`

used_memory_human 表示内存分配器 (jemalloc) 从操作系统分配的内存总量

used_memory_rss_human 表示操作系统看到的内存占用，top 命令看到的内存

used_memory_peak_human 表示 Redis 内存消耗的峰值

used_memory_lua_human 表示 lua 脚本引擎占用的内存大小

如果单个 Redis 内存占用过大，并且在业务上没有太多压缩的空间的话，可以考虑集群化了。

### 复制积压缓冲区多大？

`redis-cli info replication |grep backlog`

repl_backlog_size 表示是积压缓冲区大小

#### 作用

当「从节点」因为网络原因临时断开了「主节点」的复制，然后网络恢复了，又重新连上的时候，这段断开的时间内发生在 「主节点」上的修改操作指令都会放在积压缓冲区中，这样从库可以通过积压缓冲区恢复中断的主从同步过程。

#### 重要性 - 严重影响到主从复制的效率

积压缓冲区是环形的，则后来的指令会覆盖掉前面的内容。

所以如果「从节点」断开的时间过长，或者缓冲区的大小设置的太小，都会导致「从节点」无法快速恢复中断的主从同步过程，因为中间的修改指令被覆盖掉了。

这时候「从节点」就会进行全量同步模式，非常耗费 CPU 和网络资源。

且积压缓冲区是共享的，即便如果有多个「从节点」进行复制，它的大小也不会因此线性增长。

#### 如何知道是否需要修改 复制积压缓冲区大小？

`redis-cli info stats | grep sync`

`sync_partial_err` 表示主从半同步复制失败的次数，通过查看它来决定是否需要扩大积压缓冲区。

# 分布式锁

## 集群环境中分布式锁的不安全性

1.原先第一个客户端在「主节点」中申请成功了一把锁 Lock_1，但是 Lock_1 还没有来得及同步到「从节点」

2.「主节点」突然挂掉了，然后「从节点」变成了主节点，但是这个新的「主节点」内部没有 Lock_1

3.当另一个客户端过来请求加锁时，新的「主节点」立即就批准了，生成了另一把锁 Lock_2

这样就会导致两个客户端持有两把不同的分布式锁，因此导致集群的不安全性。

## Redlock 算法

加锁时，它会向过半节点发送 `set(key, value, nx=True, ex=xxx)` 指令，只要过半节点 set 成功，那就认为加锁成功。

释放锁时，需要向所有节点发送 `del` 指令。

除此之外，Redlock 还需要考虑出错重试、时钟漂移等很多细节问题，

同时因为 Redlock 需要向多个节点进行读写，意味着相比对单个 Redis 实例加锁性能会下降一些。

## Redisson 分布式锁

*Redisson* 是Redis官方推荐的Java版的Redis客户端。

[[Redisson基本用法](https://www.cnblogs.com/cjsblog/p/11273205.html)](https://www.cnblogs.com/cjsblog/p/11273205.html)

### 实现方式

#### Lock

默认，非公平锁，可以指定超时时间，是否异步

#### Fair Lock

#### MultiLock

#### RedLock

# 过期策略

Redis 是单线程的，在清理过期key时，也会占用线程的一部分的处理时间，如果清理的太过于繁忙，将会导致线上读写指令出现卡顿。

因此 Redis 制定了两种过期策略。

惰性策略是零散处理，定时策略是集中处理。

## 惰性策略

惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。

## 定时策略

### 过期的 key 集合

redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。

### 具体实现

Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略：

1、从过期字典中随机 20 个 key
2、删除这 20 个 key 中已经过期的 key
3、如果过期的 key 比率超过 1/4，那就重复 步骤 1

算法还增加了扫描时间的上限，默认不会超过 25ms，以此来保证扫描不会出现循环过度，线程卡死的现象。

其实导致卡顿原因还有另外一种，是内存管理器需要频繁回收内存页，这也会产生一定的 CPU 消耗。

要给过期时间设置一个随机范围，例如在目标过期时间上增加一天的随机时间，使其大量的key不会在同一时间过期。

## 从库的过期策略

从库不会进行过期扫描，从库对过期的处理是被动的。

主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。

因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在，比如上一节的集群环境分布式锁的算法漏洞就是因为这个同步延迟产生的。

# 内存淘汰策略

当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，这种交换会让 Redis 的性能急剧下降。

为了使 Redis 不出现交换行为，我们需要限制最大使用内存。

Redis 为此提供了配置参数 maxmemory 来限制内存超出期望大小。

当实际内存超出 maxmemory 时，Redis 提供了几种可选的内存淘汰策略来让用户自己决定，该如何腾出新的空间以继续提供读写服务。

## 策略类型

### noeviction

默认的淘汰策略。

不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。

这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。

### allkeys-lru

在全体 key 集合中，最少使用的 key 优先被淘汰。

### allkeys-random

在全体 key 集合中，随机进行淘汰。

### volatile-lru

在过期 key 集合中，最少使用的 key 优先被淘汰。

### volatile-random

在过期 key 集合中，随机进行淘汰。

### volatile-ttl

在过期 key 集合中，根据 key 的剩余寿命 ttl 的值进行淘汰，ttl 越小越优先被淘汰。

## 总结

allkeys-xxx 策略会对所有的 key 进行淘汰，volatile-xxx 策略只会针对带过期时间的 key 进行淘汰。

如果你只是拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。

如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key。

## 扩展 - LRU算法

实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照元素最近被访问的时间顺序进行排列。

当空间满的时候，会踢掉链表尾部的元素。

当字典的某个元素被访问时，它在链表中的位置会被移动到表头。

### Redis 使用的「近似 LRU 算法」

之所以不使用 LRU 算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。

Redis 在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。

它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。

Redis3.0 在算法中增加了淘汰池，进一步提升了近似 LRU 算法的效果。

淘汰池是一个数组，它的大小是 maxmemory_samples，在每一次淘汰循环中，新随机出来的 key 列表会和淘汰池中的 key 列表进行融合，淘汰掉最旧的一个 key 之后，保留剩余较旧的 key 列表放入淘汰池中留待下一个循环。

## 何时触发内存淘汰策略？

当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次内存淘汰，因此内存淘汰只有懒惰处理的方式。

Redis 会采样出几个key（默认为 5），然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。

如何采样就是看 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中随机，如果是 volatile 就从带过期时间的 key 字典中随机。

每次采样多少个 key 看的是 maxmemory_samples 的配置，默认为 5。
